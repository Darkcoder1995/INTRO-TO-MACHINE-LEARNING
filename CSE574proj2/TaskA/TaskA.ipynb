{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('TaskA_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>842302</th>\n",
       "      <th>M</th>\n",
       "      <th>17.99</th>\n",
       "      <th>10.38</th>\n",
       "      <th>122.8</th>\n",
       "      <th>1001</th>\n",
       "      <th>0.1184</th>\n",
       "      <th>0.2776</th>\n",
       "      <th>0.3001</th>\n",
       "      <th>0.1471</th>\n",
       "      <th>...</th>\n",
       "      <th>25.38</th>\n",
       "      <th>17.33</th>\n",
       "      <th>184.6</th>\n",
       "      <th>2019</th>\n",
       "      <th>0.1622</th>\n",
       "      <th>0.6656</th>\n",
       "      <th>0.7119</th>\n",
       "      <th>0.2654</th>\n",
       "      <th>0.4601</th>\n",
       "      <th>0.1189</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.470</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.52490</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       842302  M  17.99  10.38   122.8    1001   0.1184   0.2776   0.3001  \\\n",
       "0      842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690   \n",
       "1    84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740   \n",
       "2    84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140   \n",
       "3    84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800   \n",
       "4      843786  M  12.45  15.70   82.57   477.1  0.12780  0.17000  0.15780   \n",
       "..        ... ..    ...    ...     ...     ...      ...      ...      ...   \n",
       "563    926424  M  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390   \n",
       "564    926682  M  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400   \n",
       "565    926954  M  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251   \n",
       "566    927241  M  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140   \n",
       "567     92751  B   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000   \n",
       "\n",
       "      0.1471  ...   25.38  17.33   184.6    2019   0.1622   0.6656  0.7119  \\\n",
       "0    0.07017  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
       "1    0.12790  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
       "2    0.10520  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
       "3    0.10430  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
       "4    0.08089  ...  15.470  23.75  103.40   741.6  0.17910  0.52490  0.5355   \n",
       "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
       "563  0.13890  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
       "564  0.09791  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
       "565  0.05302  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
       "566  0.15200  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
       "567  0.00000  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
       "\n",
       "     0.2654  0.4601   0.1189  \n",
       "0    0.1860  0.2750  0.08902  \n",
       "1    0.2430  0.3613  0.08758  \n",
       "2    0.2575  0.6638  0.17300  \n",
       "3    0.1625  0.2364  0.07678  \n",
       "4    0.1741  0.3985  0.12440  \n",
       "..      ...     ...      ...  \n",
       "563  0.2216  0.2060  0.07115  \n",
       "564  0.1628  0.2572  0.06637  \n",
       "565  0.1418  0.2218  0.07820  \n",
       "566  0.2650  0.4087  0.12400  \n",
       "567  0.0000  0.2871  0.07039  \n",
       "\n",
       "[568 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashis\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "lb_make=LabelEncoder()\n",
    "# train test split\n",
    "train,test=train_test_split(df,test_size=0.2,shuffle=True)\n",
    "train_x=pd.DataFrame(np.array(train.iloc[:,2:]))\n",
    "train_y=pd.DataFrame(np.array(train.iloc[:,1]))\n",
    "test_x=pd.DataFrame(np.array(test.iloc[:,2:]))\n",
    "test_y=pd.DataFrame(np.array(test.iloc[:,1]))\n",
    "\n",
    "#normalize data\n",
    "train_x=pd.DataFrame(np.array((train_x-train_x.mean())/train_x.std()))\n",
    "test_x=pd.DataFrame(np.array((test_x-test_x.mean())/test_x.std()))\n",
    "\n",
    "#convert categorical labels into numerical\n",
    "train_y=pd.DataFrame(np.array(lb_make.fit_transform(train_y).ravel()))\n",
    "test_y=pd.DataFrame(np.array(lb_make.fit_transform(test_y).ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns Y=MX+C\n",
    "def genesis(w,train_x,c):                       \n",
    "    return np.dot(w.T,train_x.T)+c\n",
    "\n",
    "#Returns Categorical Cross Entropy Error Err=-sum(Y*log(Y_cap))+((1-Y)*log(1-y_cap)))\n",
    "def cost_func(train_y,one,pred_y):              \n",
    "    cross=-(sum(np.dot(train_y.T,np.log(pred_y).T),np.dot((one-train_y).T,np.log(one.T-pred_y).T)))\n",
    "    print(\"Cross Entropy Error is:\",np.squeeze(cross))\n",
    "    return cross\n",
    "\n",
    "#Returns Sigmoid Of The Genesis Equation\n",
    "def sigmoid1(w,train_x,c):                      \n",
    "    gen=genesis(w,train_x,c)\n",
    "    return 1/(1+np.exp(-gen))\n",
    "\n",
    "#Update Weight Gradient\n",
    "def grad_weight_update(train_x,train_y,h_init,m):      \n",
    "    return (-2/m)*(np.dot(train_x.T,(train_y.T-h_init).T))\n",
    "\n",
    "#Update C Gradient\n",
    "def grad_c_update(train_x,train_y,h_init,m):           \n",
    "    return (-2/m)*(train_y.T-h_init)\n",
    "\n",
    "#Update Weight\n",
    "def weight_update(w,alpha,train_x,train_y,h_init,m):   \n",
    "    D_w=grad_weight_update(train_x,train_y,h_init,m)\n",
    "    return w-alpha*D_w\n",
    "\n",
    "#Update C\n",
    "def c_update(c,alpha,train_x,train_y,h_init,m):       \n",
    "    D_c=grad_c_update(train_x,train_y,h_init,m)\n",
    "    return c-alpha*D_c\n",
    "\n",
    "#binarize the probabilistic solutions to calculate accuracy\n",
    "def binarize(pred_y):                                \n",
    "    bins = [0,0.5,1]\n",
    "    group_names = [0,1]\n",
    "    pred_y=np.array(pred_y)\n",
    "    return pd.DataFrame(pd.cut(pred_y[0], bins, labels=group_names))\n",
    "\n",
    "#Confusion Matrix\n",
    "def performance(train_y,pred_y_binary):            \n",
    "    tn, fp, fn, tp = confusion_matrix(train_y,pred_y_binary).ravel()\n",
    "    acc=(tp+tn)/(tp+tn+fp+fn)\n",
    "    prec=tp/(tp+fp)\n",
    "    recall=tp/(tp+fn)\n",
    "    print(\"The Factors For Train Set Are True-Negative: %s,False-Positive: %s,False-Negative: %s,True-Positive: %s\" %(tn,fp,fn,tp))\n",
    "    print('Accuracy For Train Set Is:',acc)\n",
    "    print('Precision For Train Set Is:',prec)\n",
    "    print('Recall For Train Set Is:',recall)\n",
    "    return acc\n",
    "\n",
    " #calculate performance on test data\n",
    "def test_performance(test_y,pred_y_binary):         \n",
    "    tn, fp, fn, tp = confusion_matrix(test_y,pred_y_binary).ravel()\n",
    "    acc=(tp+tn)/(tp+tn+fp+fn)\n",
    "    prec=tp/(tp+fp)\n",
    "    recall=tp/(tp+fn)\n",
    "    print(\"The Factors For Test Set Are True-Negative: %s,False-Positive: %s,False-Negative: %s,True-Positive: %s\" %(tn,fp,fn,tp))\n",
    "    print('Accuracy For Test Set Is:',acc)\n",
    "    print('Precision For Test Set Is:',prec)\n",
    "    print('Recall For Test Set Is:',recall)\n",
    "\n",
    "#logistic Regression calls sigmoid,weight and c update functions\n",
    "def logistic_regression(items):                    \n",
    "    alpha,iterations,m,w,n,c,D_w,D_c=0.001,items,len(train_y),np.zeros([30,1]),30,0,0,0\n",
    "    for i in range(iterations):\n",
    "        h_init=sigmoid1(w,train_x,c)\n",
    "        w=weight_update(w,alpha,train_x,train_y,h_init,m)\n",
    "        c=c_update(c,alpha,train_x,train_y,h_init,m)\n",
    "    return w,c,m\n",
    "\n",
    "# We calculate the Error and the Regression function and the value with the parameters corresponding to the best error function \n",
    "# is taken and then using the weights of that many number of epochs we calculate the predicted results for the test set.\n",
    "# Its observed that the cross entropy error curve stagnates at 9000 epochs upto 15000 epochs. We have calculated the results for \n",
    "# no of epochs vs error for all values at an interval of 50 units upto 1500 Epochs and its result is plotted after the function.\n",
    "\n",
    "#####################################################################################################################\n",
    "# NOTE:::: CHANGE tot_no_iter to change No Of Epochs. CHANGE VALUE IN THE LIST( PASS tot_no_iter AS A LIST) \n",
    "#####################################################################################################################\n",
    "\n",
    "def main():\n",
    "    tot_no_iter=[(i+1)*50 for i in range(100)]\n",
    "    acc,hist_w,hist_c,hist_err=[],[],[],[]\n",
    "    for no_iter in tot_no_iter:\n",
    "        w,c,m=logistic_regression(no_iter)\n",
    "        hist_w.append(pd.DataFrame(np.array(w)))\n",
    "        hist_c.append(pd.DataFrame(np.array(c)))\n",
    "        pred_y=sigmoid1(w,train_x,c)\n",
    "        one=np.ones([m,1])\n",
    "        print(\"The Performance For %s Epochs Is As Follows:\" %(no_iter))\n",
    "        cross_error=cost_func(train_y,one,pred_y)\n",
    "        hist_err.append(cross_error)\n",
    "        pred_y_binary=binarize(pred_y)\n",
    "        acc.append(performance(train_y,pred_y_binary))\n",
    "        print(\"--------------------------------------------------------\")\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    index_val=acc.index(max(acc))\n",
    "    test_w=hist_w[index_val]\n",
    "    test_c=hist_c[index_val]\n",
    "    m1=len(test_y)\n",
    "    one1=np.ones([m1,1])\n",
    "    c_1=np.squeeze(np.sum(test_c,axis=1)/m)\n",
    "    c1=np.arange(m1)\n",
    "    c1.fill(c_1)\n",
    "    pred_y_test=sigmoid1(test_w,test_x,c1)\n",
    "    cost_func(test_y,one1,pred_y_test)\n",
    "    pred_y_test_binary=binarize(pred_y_test)\n",
    "    test_performance(test_y,pred_y_test_binary)\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    plt.rcParams['figure.figsize'] = [17,5]\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle('Accuracy And Cross Entropy Error')\n",
    "    ax1.plot(tot_no_iter,np.squeeze(hist_err),color='blue')\n",
    "    ax1.set_title(\"Cross Entropy Error VS No Of Epochs\")\n",
    "    ax1.set_xlabel(\"No Of Epochs\")\n",
    "    ax1.set_ylabel(\"Cross Entropy Error\");\n",
    "    ax2.plot(tot_no_iter,acc,color='blue')\n",
    "    ax2.set_title(\"Accuracy VS No Of Epochs\")\n",
    "    ax2.set_xlabel(\"No Of Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\"); \n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Performance For 50 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 245.79624093303744\n",
      "The Factors For Train Set Are True-Negative: 260,False-Positive: 18,False-Negative: 16,True-Positive: 160\n",
      "Accuracy For Train Set Is: 0.9251101321585903\n",
      "Precision For Train Set Is: 0.898876404494382\n",
      "Recall For Train Set Is: 0.9090909090909091\n",
      "--------------------------------------------------------\n",
      "The Performance For 100 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 206.3400617908396\n",
      "The Factors For Train Set Are True-Negative: 262,False-Positive: 16,False-Negative: 16,True-Positive: 160\n",
      "Accuracy For Train Set Is: 0.9295154185022027\n",
      "Precision For Train Set Is: 0.9090909090909091\n",
      "Recall For Train Set Is: 0.9090909090909091\n",
      "--------------------------------------------------------\n",
      "The Performance For 150 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 180.93062166970137\n",
      "The Factors For Train Set Are True-Negative: 262,False-Positive: 16,False-Negative: 16,True-Positive: 160\n",
      "Accuracy For Train Set Is: 0.9295154185022027\n",
      "Precision For Train Set Is: 0.9090909090909091\n",
      "Recall For Train Set Is: 0.9090909090909091\n",
      "--------------------------------------------------------\n",
      "The Performance For 200 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 163.09176566660432\n",
      "The Factors For Train Set Are True-Negative: 262,False-Positive: 16,False-Negative: 16,True-Positive: 160\n",
      "Accuracy For Train Set Is: 0.9295154185022027\n",
      "Precision For Train Set Is: 0.9090909090909091\n",
      "Recall For Train Set Is: 0.9090909090909091\n",
      "--------------------------------------------------------\n",
      "The Performance For 250 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 149.78413276154734\n",
      "The Factors For Train Set Are True-Negative: 262,False-Positive: 16,False-Negative: 15,True-Positive: 161\n",
      "Accuracy For Train Set Is: 0.9317180616740088\n",
      "Precision For Train Set Is: 0.9096045197740112\n",
      "Recall For Train Set Is: 0.9147727272727273\n",
      "--------------------------------------------------------\n",
      "The Performance For 300 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 139.40726364512625\n",
      "The Factors For Train Set Are True-Negative: 263,False-Positive: 15,False-Negative: 15,True-Positive: 161\n",
      "Accuracy For Train Set Is: 0.933920704845815\n",
      "Precision For Train Set Is: 0.9147727272727273\n",
      "Recall For Train Set Is: 0.9147727272727273\n",
      "--------------------------------------------------------\n",
      "The Performance For 350 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 131.0399908590788\n",
      "The Factors For Train Set Are True-Negative: 263,False-Positive: 15,False-Negative: 13,True-Positive: 163\n",
      "Accuracy For Train Set Is: 0.9383259911894273\n",
      "Precision For Train Set Is: 0.9157303370786517\n",
      "Recall For Train Set Is: 0.9261363636363636\n",
      "--------------------------------------------------------\n",
      "The Performance For 400 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 124.11469115244097\n",
      "The Factors For Train Set Are True-Negative: 264,False-Positive: 14,False-Negative: 12,True-Positive: 164\n",
      "Accuracy For Train Set Is: 0.9427312775330396\n",
      "Precision For Train Set Is: 0.9213483146067416\n",
      "Recall For Train Set Is: 0.9318181818181818\n",
      "--------------------------------------------------------\n",
      "The Performance For 450 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 118.2623264736129\n",
      "The Factors For Train Set Are True-Negative: 265,False-Positive: 13,False-Negative: 12,True-Positive: 164\n",
      "Accuracy For Train Set Is: 0.9449339207048458\n",
      "Precision For Train Set Is: 0.9265536723163842\n",
      "Recall For Train Set Is: 0.9318181818181818\n",
      "--------------------------------------------------------\n",
      "The Performance For 500 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 113.23236520852986\n",
      "The Factors For Train Set Are True-Negative: 265,False-Positive: 13,False-Negative: 12,True-Positive: 164\n",
      "Accuracy For Train Set Is: 0.9449339207048458\n",
      "Precision For Train Set Is: 0.9265536723163842\n",
      "Recall For Train Set Is: 0.9318181818181818\n",
      "--------------------------------------------------------\n",
      "The Performance For 550 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 108.84855419163941\n",
      "The Factors For Train Set Are True-Negative: 265,False-Positive: 13,False-Negative: 10,True-Positive: 166\n",
      "Accuracy For Train Set Is: 0.9493392070484582\n",
      "Precision For Train Set Is: 0.9273743016759777\n",
      "Recall For Train Set Is: 0.9431818181818182\n",
      "--------------------------------------------------------\n",
      "The Performance For 600 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 104.98312719119122\n",
      "The Factors For Train Set Are True-Negative: 265,False-Positive: 13,False-Negative: 10,True-Positive: 166\n",
      "Accuracy For Train Set Is: 0.9493392070484582\n",
      "Precision For Train Set Is: 0.9273743016759777\n",
      "Recall For Train Set Is: 0.9431818181818182\n",
      "--------------------------------------------------------\n",
      "The Performance For 650 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 101.54106934613182\n",
      "The Factors For Train Set Are True-Negative: 265,False-Positive: 13,False-Negative: 10,True-Positive: 166\n",
      "Accuracy For Train Set Is: 0.9493392070484582\n",
      "Precision For Train Set Is: 0.9273743016759777\n",
      "Recall For Train Set Is: 0.9431818181818182\n",
      "--------------------------------------------------------\n",
      "The Performance For 700 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 98.45014337760594\n",
      "The Factors For Train Set Are True-Negative: 266,False-Positive: 12,False-Negative: 10,True-Positive: 166\n",
      "Accuracy For Train Set Is: 0.9515418502202643\n",
      "Precision For Train Set Is: 0.9325842696629213\n",
      "Recall For Train Set Is: 0.9431818181818182\n",
      "--------------------------------------------------------\n",
      "The Performance For 750 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 95.65435805018691\n",
      "The Factors For Train Set Are True-Negative: 266,False-Positive: 12,False-Negative: 9,True-Positive: 167\n",
      "Accuracy For Train Set Is: 0.9537444933920705\n",
      "Precision For Train Set Is: 0.9329608938547486\n",
      "Recall For Train Set Is: 0.9488636363636364\n",
      "--------------------------------------------------------\n",
      "The Performance For 800 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 93.10956834422159\n",
      "The Factors For Train Set Are True-Negative: 266,False-Positive: 12,False-Negative: 9,True-Positive: 167\n",
      "Accuracy For Train Set Is: 0.9537444933920705\n",
      "Precision For Train Set Is: 0.9329608938547486\n",
      "Recall For Train Set Is: 0.9488636363636364\n",
      "--------------------------------------------------------\n",
      "The Performance For 850 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 90.78043757566131\n",
      "The Factors For Train Set Are True-Negative: 267,False-Positive: 11,False-Negative: 9,True-Positive: 167\n",
      "Accuracy For Train Set Is: 0.9559471365638766\n",
      "Precision For Train Set Is: 0.9382022471910112\n",
      "Recall For Train Set Is: 0.9488636363636364\n",
      "--------------------------------------------------------\n",
      "The Performance For 900 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 88.63829376233404\n",
      "The Factors For Train Set Are True-Negative: 267,False-Positive: 11,False-Negative: 9,True-Positive: 167\n",
      "Accuracy For Train Set Is: 0.9559471365638766\n",
      "Precision For Train Set Is: 0.9382022471910112\n",
      "Recall For Train Set Is: 0.9488636363636364\n",
      "--------------------------------------------------------\n",
      "The Performance For 950 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 86.6595874713673\n",
      "The Factors For Train Set Are True-Negative: 267,False-Positive: 11,False-Negative: 9,True-Positive: 167\n",
      "Accuracy For Train Set Is: 0.9559471365638766\n",
      "Precision For Train Set Is: 0.9382022471910112\n",
      "Recall For Train Set Is: 0.9488636363636364\n",
      "--------------------------------------------------------\n",
      "The Performance For 1000 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 84.82476298104993\n",
      "The Factors For Train Set Are True-Negative: 268,False-Positive: 10,False-Negative: 9,True-Positive: 167\n",
      "Accuracy For Train Set Is: 0.9581497797356828\n",
      "Precision For Train Set Is: 0.943502824858757\n",
      "Recall For Train Set Is: 0.9488636363636364\n",
      "--------------------------------------------------------\n",
      "The Performance For 1050 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 83.11741893604575\n",
      "The Factors For Train Set Are True-Negative: 268,False-Positive: 10,False-Negative: 8,True-Positive: 168\n",
      "Accuracy For Train Set Is: 0.960352422907489\n",
      "Precision For Train Set Is: 0.9438202247191011\n",
      "Recall For Train Set Is: 0.9545454545454546\n",
      "--------------------------------------------------------\n",
      "The Performance For 1100 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 81.52367528004405\n",
      "The Factors For Train Set Are True-Negative: 269,False-Positive: 9,False-Negative: 8,True-Positive: 168\n",
      "Accuracy For Train Set Is: 0.9625550660792952\n",
      "Precision For Train Set Is: 0.9491525423728814\n",
      "Recall For Train Set Is: 0.9545454545454546\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Performance For 1150 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 80.0316894691968\n",
      "The Factors For Train Set Are True-Negative: 269,False-Positive: 9,False-Negative: 8,True-Positive: 168\n",
      "Accuracy For Train Set Is: 0.9625550660792952\n",
      "Precision For Train Set Is: 0.9491525423728814\n",
      "Recall For Train Set Is: 0.9545454545454546\n",
      "--------------------------------------------------------\n",
      "The Performance For 1200 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 78.63128225527987\n",
      "The Factors For Train Set Are True-Negative: 270,False-Positive: 8,False-Negative: 8,True-Positive: 168\n",
      "Accuracy For Train Set Is: 0.9647577092511013\n",
      "Precision For Train Set Is: 0.9545454545454546\n",
      "Recall For Train Set Is: 0.9545454545454546\n",
      "--------------------------------------------------------\n",
      "The Performance For 1250 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 77.3136449400489\n",
      "The Factors For Train Set Are True-Negative: 270,False-Positive: 8,False-Negative: 8,True-Positive: 168\n",
      "Accuracy For Train Set Is: 0.9647577092511013\n",
      "Precision For Train Set Is: 0.9545454545454546\n",
      "Recall For Train Set Is: 0.9545454545454546\n",
      "--------------------------------------------------------\n",
      "The Performance For 1300 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 76.07110793802653\n",
      "The Factors For Train Set Are True-Negative: 271,False-Positive: 7,False-Negative: 8,True-Positive: 168\n",
      "Accuracy For Train Set Is: 0.9669603524229075\n",
      "Precision For Train Set Is: 0.96\n",
      "Recall For Train Set Is: 0.9545454545454546\n",
      "--------------------------------------------------------\n",
      "The Performance For 1350 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 74.89695599282582\n",
      "The Factors For Train Set Are True-Negative: 271,False-Positive: 7,False-Negative: 8,True-Positive: 168\n",
      "Accuracy For Train Set Is: 0.9669603524229075\n",
      "Precision For Train Set Is: 0.96\n",
      "Recall For Train Set Is: 0.9545454545454546\n",
      "--------------------------------------------------------\n",
      "The Performance For 1400 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 73.78527926908941\n",
      "The Factors For Train Set Are True-Negative: 271,False-Positive: 7,False-Negative: 8,True-Positive: 168\n",
      "Accuracy For Train Set Is: 0.9669603524229075\n",
      "Precision For Train Set Is: 0.96\n",
      "Recall For Train Set Is: 0.9545454545454546\n",
      "--------------------------------------------------------\n",
      "The Performance For 1450 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 72.73085230631975\n",
      "The Factors For Train Set Are True-Negative: 272,False-Positive: 6,False-Negative: 8,True-Positive: 168\n",
      "Accuracy For Train Set Is: 0.9691629955947136\n",
      "Precision For Train Set Is: 0.9655172413793104\n",
      "Recall For Train Set Is: 0.9545454545454546\n",
      "--------------------------------------------------------\n",
      "The Performance For 1500 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 71.72903481490812\n",
      "The Factors For Train Set Are True-Negative: 272,False-Positive: 6,False-Negative: 8,True-Positive: 168\n",
      "Accuracy For Train Set Is: 0.9691629955947136\n",
      "Precision For Train Set Is: 0.9655172413793104\n",
      "Recall For Train Set Is: 0.9545454545454546\n",
      "--------------------------------------------------------\n",
      "The Performance For 1550 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 70.77568974870509\n",
      "The Factors For Train Set Are True-Negative: 272,False-Positive: 6,False-Negative: 7,True-Positive: 169\n",
      "Accuracy For Train Set Is: 0.9713656387665198\n",
      "Precision For Train Set Is: 0.9657142857142857\n",
      "Recall For Train Set Is: 0.9602272727272727\n",
      "--------------------------------------------------------\n",
      "The Performance For 1600 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 69.8671151593924\n",
      "The Factors For Train Set Are True-Negative: 272,False-Positive: 6,False-Negative: 7,True-Positive: 169\n",
      "Accuracy For Train Set Is: 0.9713656387665198\n",
      "Precision For Train Set Is: 0.9657142857142857\n",
      "Recall For Train Set Is: 0.9602272727272727\n",
      "--------------------------------------------------------\n",
      "The Performance For 1650 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 68.99998713407905\n",
      "The Factors For Train Set Are True-Negative: 272,False-Positive: 6,False-Negative: 7,True-Positive: 169\n",
      "Accuracy For Train Set Is: 0.9713656387665198\n",
      "Precision For Train Set Is: 0.9657142857142857\n",
      "Recall For Train Set Is: 0.9602272727272727\n",
      "--------------------------------------------------------\n",
      "The Performance For 1700 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 68.1713117146949\n",
      "The Factors For Train Set Are True-Negative: 272,False-Positive: 6,False-Negative: 7,True-Positive: 169\n",
      "Accuracy For Train Set Is: 0.9713656387665198\n",
      "Precision For Train Set Is: 0.9657142857142857\n",
      "Recall For Train Set Is: 0.9602272727272727\n",
      "--------------------------------------------------------\n",
      "The Performance For 1750 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 67.37838414944144\n",
      "The Factors For Train Set Are True-Negative: 272,False-Positive: 6,False-Negative: 7,True-Positive: 169\n",
      "Accuracy For Train Set Is: 0.9713656387665198\n",
      "Precision For Train Set Is: 0.9657142857142857\n",
      "Recall For Train Set Is: 0.9602272727272727\n",
      "--------------------------------------------------------\n",
      "The Performance For 1800 Epochs Is As Follows:\n",
      "Cross Entropy Error is: 66.61875417099745\n",
      "The Factors For Train Set Are True-Negative: 272,False-Positive: 6,False-Negative: 7,True-Positive: 169\n",
      "Accuracy For Train Set Is: 0.9713656387665198\n",
      "Precision For Train Set Is: 0.9657142857142857\n",
      "Recall For Train Set Is: 0.9602272727272727\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-fc6b3276e01c>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhist_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhist_c\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhist_err\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mno_iter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtot_no_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0mhist_w\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mhist_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-fc6b3276e01c>\u001b[0m in \u001b[0;36mlogistic_regression\u001b[1;34m(items)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mh_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigmoid1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-fc6b3276e01c>\u001b[0m in \u001b[0;36mweight_update\u001b[1;34m(w, alpha, train_x, train_y, h_init, m)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#Update Weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mweight_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mD_w\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_weight_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mD_w\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-fc6b3276e01c>\u001b[0m in \u001b[0;36mgrad_weight_update\u001b[1;34m(train_x, train_y, h_init, m)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#Update Weight Gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgrad_weight_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mh_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#Update C Gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following graph is the result of calculating accuracy vs no of epochs.\n",
      "Here we have calculated it upto 15000 epochs by starting from 50 epochs and plotted the accuracy vs no of epochs \n",
      "and Cross Entropy Error vs no of epochs.\n",
      "The total number of iterations was set by tot_no_iter=[(i+1)*50 for i in range(300)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The following graph is the result of calculating accuracy vs no of epochs.\")\n",
    "print(\"Here we have calculated it upto 15000 epochs by starting from 50 epochs and plotted the accuracy vs no of epochs \")\n",
    "print(\"and Cross Entropy Error vs no of epochs.\")\n",
    "print(\"The total number of iterations was set by tot_no_iter=[(i+1)*50 for i in range(300)]\")\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='download.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
